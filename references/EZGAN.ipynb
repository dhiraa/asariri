{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an illustration of a very simple generative adversarial network, built with TensorFlow. It generates images that look like handwritten digits from the MNIST dataset.\n",
    "\n",
    "\n",
    "The code here is written for TensorFlow v0.12, but can be made to run on earlier versions with some quick changes—in particular, replacing `tf.global_variable_initializer()` with `tf.initialize_all_variables()`. This script sends very helpful output to TensorBoard; to make it work with TensorBoard v0.11 and earlier, replace `tf.summary.scalar()` and `tf.summary.image()` with `tf.scalar_summary()` and `tf.image_summary()`, respectively.\n",
    "\n",
    "- This is a Deep Convolutional GAN\n",
    "- The generator is a deconvolutional net\n",
    "- The discriminator is a convolutional net\n",
    "- Watch a GAN train https://www.youtube.com/watch?v=fN3egtFdA7s\n",
    "\n",
    "The authors improved on the vanilla GAN by finding that\n",
    "\n",
    "- Batch normalization is a must in both networks. https://standardfrancis.files.wordpress.com/2015/04/screenshot-from-2015-04-16-133436.png?w=1008 Batch normalization potentially helps in two ways: faster learning and higher overall accuracy. The improved method also allows you to use a higher learning rate, potentially providing another boost in speed. normalization is often used as a pre-processing step to make the data comparable across features. batch normalizations is doing it everywhere\n",
    "- ReLU activations are your friend (almost always).\n",
    "\n",
    "\n",
    "\n",
    "GANS are hard to train\n",
    "\n",
    "Without the right hyperparameters, network architecture, and training procedure, \n",
    "there is a high chance that either the generator or discriminator will overpower the other. \n",
    "\n",
    "A common case of this is the situation where the generator is able to find a flaw in the discriminator \n",
    "by repeatedly outputting an image that fits the data distribution the discriminator is looking for, \n",
    "but is nowhere close to being a readable MNIST digit. The generator has collapsed onto a single point, \n",
    "and therefore we won’t output a variety of digits.\n",
    "\n",
    "There are also cases where the discriminator becomes\n",
    "too powerful and is able to easily make the distinction between real and fake images.\n",
    "\n",
    "\n",
    "The mathematical intuition behind this phenomenon lies in that GANs are typically trained using gradient \n",
    "descent techniques that are designed to find the minimum value of a cost function, rather than to find \n",
    "the Nash equilibrium of a game. When used to seek for a Nash equilibrium, these algorithms may fail to \n",
    "converge. Further research into game theory and stable optimization techniques may result in GANs that \n",
    "are as easy to train as ConvNets!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Yaktocat](https://cdn-images-1.medium.com/max/2000/1*39Nnni_nhPDaLu9AnTLoWw.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf #machine learning\n",
    "import numpy as np #matrix math\n",
    "import datetime #logging the time for model checkpoints and training\n",
    "import matplotlib.pyplot as plt #visualize results\n",
    "%matplotlib inline\n",
    "\n",
    "#Step 1 - Collect dataset\n",
    "#MNIST - handwritten character digits ~50K training and validation images + labels, 10K testing\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#will ensure that the correct data has been downloaded to your \n",
    "#local training folder and then unpack that data to return a dictionary of DataSet instances.\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Yaktocat](https://image.slidesharecdn.com/tensorflowppt-160408142819/95/tensorflow-4-638.jpg?cb=1460125744)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a clever structure suggested by [Adit Deshpande](https://adeshpande3.github.io/), the discriminator and generator networks will sit inside separate functions that we can call as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the discriminator network. It takes `x_image` and returns a real/fake classification. As you'll see below, we can either feed `x_image` through a placeholder, or from another tensor—for instance, the output of the generator.\n",
    "\n",
    "This network structure is taken directly from TensorFlow's [Deep MNIST for Experts](https://www.tensorflow.org/tutorials/mnist/pros/) tutorial.\n",
    "\n",
    "![Image of Yaktocat](https://ai2-s2-public.s3.amazonaws.com/figures/2016-11-08/42f6f5454dda99d8989f9814989efd50fe807ee8/3-Figure1-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(x_image, reuse=False):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "        # First convolutional and pool layers\n",
    "        # These search for 32 different 5 x 5 pixel features\n",
    "        #We’ll start off by passing the image through a convolutional layer. \n",
    "        #First, we create our weight and bias variables through tf.get_variable. \n",
    "        #Our first weight matrix (or filter) will be of size 5x5 and will have a output depth of 32. \n",
    "        #It will be randomly initialized from a normal distribution.\n",
    "        d_w1 = tf.get_variable('d_w1', [5, 5, 1, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        #tf.constant_init generates tensors with constant values.\n",
    "        d_b1 = tf.get_variable('d_b1', [32], initializer=tf.constant_initializer(0))\n",
    "        #tf.nn.conv2d() is the Tensorflow’s function for a common convolution.\n",
    "        #It takes in 4 arguments. The first is the input volume (our 28 x 28 x 1 image in this case). \n",
    "        #The next argument is the filter/weight matrix. Finally, you can also change the stride and \n",
    "        #padding of the convolution. Those two values affect the dimensions of the output volume.\n",
    "        #\"SAME\" tries to pad evenly left and right, but if the amount of columns to be added is odd, \n",
    "        #it will add the extra column to the right,\n",
    "        #strides = [batch, height, width, channels]\n",
    "        d1 = tf.nn.conv2d(input=x_image, filter=d_w1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        #add the bias\n",
    "        d1 = d1 + d_b1\n",
    "        #squash with nonlinearity (ReLU)\n",
    "        d1 = tf.nn.relu(d1)\n",
    "        ##An average pooling layer performs down-sampling by dividing the input into \n",
    "        #rectangular pooling regions and computing the average of each region. \n",
    "        #It returns the averages for the pooling regions.\n",
    "        d1 = tf.nn.avg_pool(d1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "        #As with any convolutional neural network, this module is repeated, \n",
    "        # Second convolutional and pool layers\n",
    "        # These search for 64 different 5 x 5 pixel features\n",
    "        d_w2 = tf.get_variable('d_w2', [5, 5, 32, 64], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b2 = tf.get_variable('d_b2', [64], initializer=tf.constant_initializer(0))\n",
    "        d2 = tf.nn.conv2d(input=d1, filter=d_w2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        d2 = d2 + d_b2\n",
    "        d2 = tf.nn.relu(d2)\n",
    "        d2 = tf.nn.avg_pool(d2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "         #and then followed by a series of fully connected layers. \n",
    "        # First fully connected layer\n",
    "        d_w3 = tf.get_variable('d_w3', [7 * 7 * 64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b3 = tf.get_variable('d_b3', [1024], initializer=tf.constant_initializer(0))\n",
    "        d3 = tf.reshape(d2, [-1, 7 * 7 * 64])\n",
    "        d3 = tf.matmul(d3, d_w3)\n",
    "        d3 = d3 + d_b3\n",
    "        d3 = tf.nn.relu(d3)\n",
    "\n",
    "        #The last fully-connected layer holds the output, such as the class scores.\n",
    "        # Second fully connected layer\n",
    "        d_w4 = tf.get_variable('d_w4', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        d_b4 = tf.get_variable('d_b4', [1], initializer=tf.constant_initializer(0))\n",
    "\n",
    "        #At the end of the network, we do a final matrix multiply and \n",
    "        #return the activation value. \n",
    "        #For those of you comfortable with CNNs, this is just a simple binary classifier. Nothing fancy.\n",
    "        # Final layer\n",
    "        d4 = tf.matmul(d3, d_w4) + d_b4\n",
    "        # d4 dimensions: batch_size x 1\n",
    "\n",
    "        return d4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the generator. When it's called, it starts by creating a batch of random noise from the latente space $z$, then passes it through a handful of convolutions to produce a 28 x 28 image.\n",
    "\n",
    "This structure is borrowed [from Tim O'Shea](http://www.kdnuggets.com/2016/07/mnist-generative-adversarial-model-keras.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#You can think of the generator as being a kind of reverse ConvNet. With CNNs, the goal is to \n",
    "#transform a 2 or 3 dimensional matrix of pixel values into a single probability. A generator, \n",
    "#however, seeks to take a d-dimensional noise vector and upsample it to become a 28 x 28 image. \n",
    "#ReLUs are then used to stabilize the outputs of each layer.\n",
    "#example of CNN blocks http://cs231n.github.io/convolutional-networks/#fc\n",
    "\n",
    "#it takes random inputs, and eventually mapping them down to a [1,28,28] pixel to match the MNIST data shape.  \n",
    "#Be begin by generating a dense 14×14 set of values, and then run through a handful of filters of\n",
    "#varying sizes and numbers of channels\n",
    "#weight matrices get progressively smaller\n",
    "\n",
    "def generator(batch_size, z_dim, reuse=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        if (reuse):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "                \n",
    "        z = tf.truncated_normal([batch_size, z_dim], mean=0, stddev=1, name='z')\n",
    "        #first deconv block\n",
    "        g_w1 = tf.get_variable('g_w1', [z_dim, 3136], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        g_b1 = tf.get_variable('g_b1', [3136], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        g1 = tf.matmul(z, g_w1) + g_b1\n",
    "        g1 = tf.reshape(g1, [-1, 56, 56, 1])\n",
    "        g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope='bn1')\n",
    "        g1 = tf.nn.relu(g1)\n",
    "\n",
    "        # Generate 50 features\n",
    "        g_w2 = tf.get_variable('g_w2', [3, 3, 1, z_dim/2], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        g_b2 = tf.get_variable('g_b2', [z_dim/2], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        g2 = tf.nn.conv2d(g1, g_w2, strides=[1, 2, 2, 1], padding='SAME')\n",
    "        g2 = g2 + g_b2\n",
    "        g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope='bn2')\n",
    "        g2 = tf.nn.relu(g2)\n",
    "        g2 = tf.image.resize_images(g2, [56, 56])\n",
    "\n",
    "        # Generate 25 features\n",
    "        g_w3 = tf.get_variable('g_w3', [3, 3, z_dim/2, z_dim/4], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        g_b3 = tf.get_variable('g_b3', [z_dim/4], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        g3 = tf.nn.conv2d(g2, g_w3, strides=[1, 2, 2, 1], padding='SAME')\n",
    "        g3 = g3 + g_b3\n",
    "        g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope='bn3')\n",
    "        g3 = tf.nn.relu(g3)\n",
    "        g3 = tf.image.resize_images(g3, [56, 56])\n",
    "\n",
    "        # Final convolution with one output channel\n",
    "        g_w4 = tf.get_variable('g_w4', [1, 1, z_dim/4, 1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        g_b4 = tf.get_variable('g_b4', [1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        g4 = tf.nn.conv2d(g3, g_w4, strides=[1, 2, 2, 1], padding='SAME')\n",
    "        g4 = g4 + g_b4\n",
    "        g4 = tf.sigmoid(g4)\n",
    "\n",
    "        # No batch normalization at the final layer, but we do add\n",
    "        # a sigmoid activator to make the generated images crisper.\n",
    "        # Dimensions of g4: batch_size x 28 x 28 x 1\n",
    "\n",
    "        return g4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set up our losses and optimizers.\n",
    "\n",
    "- The upside-down capital delta symbol denotse the gradient of the generator\n",
    "- m is the number of samples\n",
    "- Sigma notation tells you to sum up the function evaluated at particular points determined by the little numbers on top and below the big sigma. It is used to add a series of numbers.\n",
    "\n",
    "![Image of Yaktocat](https://cdn-images-1.medium.com/max/1600/1*V4nu4ThcHFQXmWKxx9lhbA.png)\n",
    "The gradient ascent expression for the discriminator. The first term corresponds to optimizing the probability that the real data (x) is rated highly. The second term corresponds to optimizing the probability that the generated data G(z) is rated poorly. Notice we apply the gradient to the discriminator, not the generator.\n",
    "\n",
    "Gradient methods generally work better optimizing log⁡p(x) than p(x) because the gradient of log⁡p(x) is generally more well-scaled. That is, it has a size that consistently and helpfully reflects the objective function's geometry, making it easier to select an appropriate step size and get to the optimum in fewer steps. The computer uses a limited digit floating point representation of fractions, multiplying so many probabilities is guaranteed to be very very close to zero. With log, we don't have this issue.\n",
    "\n",
    "The generator is then optimized in order to increase the probability of the generated data being rated highly.\n",
    "\n",
    "![Image of Yaktocat](https://cdn-images-1.medium.com/max/1600/1*njOrO3uNzUH1dZb7-i-dhw.png)\n",
    "The gradient descent expression for the generator. The term corresponds to optimizing the probability that the generated data G(z) is rated highly. Notice we apply the gradient to the generator network, not the discriminator.\n",
    "\n",
    "By alternating gradient optimization between the two networks using these expressions on new batches of real and generated data each time, the GAN will slowly converge to producing data that is as realistic as the network is capable of modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "batch_size = 50\n",
    "z_dimensions = 100\n",
    "\n",
    "x_placeholder = tf.placeholder(\"float\", shape = [None,28,28,1], name='x_placeholder')\n",
    "# x_placeholder is for feeding input images to the discriminator\n",
    "\n",
    "#One of the trickiest parts about understanding GANs is that the loss function is a little bit more complex than that\n",
    "#of a traditional CNN classifiers (For those, a simple MSE or Hinge Loss would do the trick). \n",
    "#If you think back to the introduction, a GAN can be thought of as a zero sum minimax game. \n",
    "#The generator is constantly improving to produce more and more realistic images, while the discriminator is \n",
    "#trying to get better and better at distinguishing between real and generated images.\n",
    "#This means that we need to formulate loss functions that affect both networks. \n",
    "#Let’s take a look at the inputs and outputs of our networks.\n",
    "\n",
    "Gz = generator(batch_size, z_dimensions)\n",
    "# Gz holds the generated images\n",
    "#g(z)\n",
    "\n",
    "Dx = discriminator(x_placeholder)\n",
    "# Dx hold the discriminator's prediction probabilities\n",
    "# for real MNIST images\n",
    "#d(x)\n",
    "\n",
    "Dg = discriminator(Gz, reuse=True)\n",
    "# Dg holds discriminator prediction probabilities for generated images\n",
    "#d(g(z))\n",
    "\n",
    "\n",
    "\n",
    "#So, let’s first think about what we want out of our networks. We want the generator network to create \n",
    "#images that will fool the discriminator. The generator wants the discriminator to output a 1 (positive example).\n",
    "#Therefore, we want to compute the loss between the Dg and label of 1. This can be done through \n",
    "#the tf.nn.sigmoid_cross_entropy_with_logits function. This means that the cross entropy loss will \n",
    "#be taken between the two arguments. The \"with_logits\" component means that the function will operate \n",
    "#on unscaled values. Basically, this means that instead of using a softmax function to squish the output\n",
    "#activations to probability values from 0 to 1, we simply return the unscaled value of the matrix multiplication.\n",
    "#Take a look at the last line of our discriminator. There's no softmax or sigmoid layer at the end.\n",
    "#The reduce mean function just takes the mean value of all of the components in the matrixx returned \n",
    "#by the cross entropy function. This is just a way of reducing the loss to a single scalar value, \n",
    "#instead of a vector or matrix.\n",
    "#https://datascience.stackexchange.com/questions/9302/the-cross-entropy-error-function-in-neural-networks\n",
    "\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.ones_like(Dg)))\n",
    "\n",
    "\n",
    "#Now, let’s think about the discriminator’s point of view. Its goal is to just get the correct labels \n",
    "#(output 1 for each MNIST digit and 0 for the generated ones). We’d like to compute the loss between Dx \n",
    "#and the correct label of 1 as well as the loss between Dg and the correct label of 0.\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dx, labels=tf.fill([batch_size, 1], 0.9)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.zeros_like(Dg)))\n",
    "d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]\n",
    "\n",
    "# Train the discriminator\n",
    "# Increasing from 0.001 in GitHub version\n",
    "with tf.variable_scope(tf.get_variable_scope(), reuse=False) as scope:\n",
    "    #Next, we specify our two optimizers. In today’s era of deep learning, Adam seems to be the\n",
    "    #best SGD optimizer as it utilizes adaptive learning rates and momentum. \n",
    "    #We call Adam's minimize function and also specify the variables that we want it to update.\n",
    "    d_trainer_fake = tf.train.AdamOptimizer(0.0001).minimize(d_loss_fake, var_list=d_vars)\n",
    "    d_trainer_real = tf.train.AdamOptimizer(0.0001).minimize(d_loss_real, var_list=d_vars)\n",
    "\n",
    "    # Train the generator\n",
    "    # Decreasing from 0.004 in GitHub version\n",
    "    g_trainer = tf.train.AdamOptimizer(0.0001).minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's where we pass helpful summary scalars and sample images to TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard/gan/\n"
     ]
    }
   ],
   "source": [
    "#Outputs a Summary protocol buffer containing a single scalar value.\n",
    "tf.summary.scalar('Generator_loss', g_loss)\n",
    "tf.summary.scalar('Discriminator_loss_real', d_loss_real)\n",
    "tf.summary.scalar('Discriminator_loss_fake', d_loss_fake)\n",
    "\n",
    "d_real_count_ph = tf.placeholder(tf.float32)\n",
    "d_fake_count_ph = tf.placeholder(tf.float32)\n",
    "g_count_ph = tf.placeholder(tf.float32)\n",
    "\n",
    "tf.summary.scalar('d_real_count', d_real_count_ph)\n",
    "tf.summary.scalar('d_fake_count', d_fake_count_ph)\n",
    "tf.summary.scalar('g_count', g_count_ph)\n",
    "\n",
    "# Sanity check to see how the discriminator evaluates\n",
    "# generated and real MNIST images\n",
    "d_on_generated = tf.reduce_mean(discriminator(generator(batch_size, z_dimensions, reuse=True), reuse=True))\n",
    "d_on_real = tf.reduce_mean(discriminator(x_placeholder, reuse=True))\n",
    " \n",
    "tf.summary.scalar('d_on_generated_eval', d_on_generated)\n",
    "tf.summary.scalar('d_on_real_eval', d_on_real)\n",
    "\n",
    "images_for_tensorboard = generator(batch_size, z_dimensions, reuse=True)\n",
    "tf.summary.image('Generated_images', images_for_tensorboard, 10)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/gan/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)\n",
    "print(logdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to eventually reach a point where the discriminator correctly classifies nearly all real MNIST images as MNIST images, and classifies generated images as MNIST images about 50% of the time. There are several failure modes that we need to avoid:\n",
    "* **Discriminator losses approach zero**: this leaves practically no gradients for the generator's optimizer.\n",
    "* **Discriminator losses rise unbounded on generated images**: similarly, this leaves practically no gradient for the discriminator to improve, and the generator's training stalls, too, since the gradients it's reading suggest that it has achieved perfect performance.\n",
    "* **Divergent discriminator accuracy**: the discriminator learns a shortcut by either classifying everything as real or everything as generated. You can detect this by checking the discriminator's losses on generated images against the discriminator's losses on real images.\n",
    "\n",
    "To stay balanced between these, we use a controller in the training loop that runs each of the three training operations depending on their losses. Qualitatively speaking, the most rapid improvements in output come when the generator and discriminator are evenly matched; the controller avoids running a training operation when its network shows signs of overpowering the others.\n",
    "\n",
    "Here's our training loop. You'll need a writable directory in your current working directory called `tensorboard` for TensorBoard logs, and another one called `models` to store the five most recent checkpoints.\n",
    "\n",
    "Recognizable results should begin to appear before 10,000 cycles, and will improve after that. On a fast GPU machine, you can make it to 10,000 cycles in less than 10 minutes. It could take around 10 times as long to run on a desktop CPU. There are lots of random numbers involved, so you'll get different results every time you run this. In particular, it's likely to stall for upwards of 2,000 cycles at a time early on, but it should recover on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[Node: Placeholder_2 = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder_2', defined at:\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-c213fcb95dd2>\", line 8, in <module>\n    g_count_ph = tf.placeholder(tf.float32)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1599, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3091, in _placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[Node: Placeholder_2 = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[Node: Placeholder_2 = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-5580c3ecb89c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mreal_image_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         summary = sess.run(merged, {x_placeholder: real_image_batch, d_real_count_ph: d_real_count,\n\u001b[0;32m---> 41\u001b[0;31m                                     d_fake_count_ph: d_fake_count, g_count_ph: g_count})\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0md_real_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_fake_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[Node: Placeholder_2 = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder_2', defined at:\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-c213fcb95dd2>\", line 8, in <module>\n    g_count_ph = tf.placeholder(tf.float32)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1599, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3091, in _placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/mageswarand/anaconda3/envs/tensorflow1.0/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_2' with dtype float\n\t [[Node: Placeholder_2 = Placeholder[dtype=DT_FLOAT, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#During every iteration, there will be two updates being made, one to the discriminator and one to the generator. \n",
    "#For the generator update, we’ll feed in a random z vector to the generator and pass that output to the discriminator\n",
    "#to obtain a probability score (this is the Dg variable we specified earlier).\n",
    "#As we remember from our loss function, the cross entropy loss gets minimized, \n",
    "#and only the generator’s weights and biases get updated.\n",
    "#We'll do the same for the discriminator update. We’ll be taking a batch of images \n",
    "#from the mnist variable we created way at the beginning of our program.\n",
    "#These will serve as the positive examples, while the images in the previous section are the negative ones.\n",
    "\n",
    "gLoss = 0\n",
    "dLossFake, dLossReal = 1, 1\n",
    "d_real_count, d_fake_count, g_count = 0, 0, 0\n",
    "for i in range(50000):\n",
    "    real_image_batch = mnist.train.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n",
    "    if dLossFake > 0.6:\n",
    "        # Train discriminator on generated images\n",
    "        _, dLossReal, dLossFake, gLoss = sess.run([d_trainer_fake, d_loss_real, d_loss_fake, g_loss],\n",
    "                                                    {x_placeholder: real_image_batch})\n",
    "        d_fake_count += 1\n",
    "\n",
    "    if gLoss > 0.5:\n",
    "        # Train the generator\n",
    "        _, dLossReal, dLossFake, gLoss = sess.run([g_trainer, d_loss_real, d_loss_fake, g_loss],\n",
    "                                                    {x_placeholder: real_image_batch})\n",
    "        g_count += 1\n",
    "\n",
    "    if dLossReal > 0.45:\n",
    "        # If the discriminator classifies real images as fake,\n",
    "        # train discriminator on real values\n",
    "        _, dLossReal, dLossFake, gLoss = sess.run([d_trainer_real, d_loss_real, d_loss_fake, g_loss],\n",
    "                                                    {x_placeholder: real_image_batch})\n",
    "        d_real_count += 1\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        real_image_batch = mnist.validation.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n",
    "        summary = sess.run(merged, {x_placeholder: real_image_batch, d_real_count_ph: d_real_count,\n",
    "                                    d_fake_count_ph: d_fake_count, g_count_ph: g_count})\n",
    "        writer.add_summary(summary, i)\n",
    "        d_real_count, d_fake_count, g_count = 0, 0, 0\n",
    "\n",
    "    if i % 1000 == 0:\n",
    "        # Periodically display a sample image in the notebook\n",
    "        # (These are also being sent to TensorBoard every 10 iterations)\n",
    "        images = sess.run(generator(3, z_dimensions))\n",
    "        d_result = sess.run(discriminator(x_placeholder), {x_placeholder: images})\n",
    "        print(\"TRAINING STEP\", i, \"AT\", datetime.datetime.now())\n",
    "        for j in range(3):\n",
    "            print(\"Discriminator classification\", d_result[j])\n",
    "            im = images[j, :, :, 0]\n",
    "            plt.imshow(im.reshape([28, 28]), cmap='Greys')\n",
    "            plt.show()\n",
    "\n",
    "    if i % 5000 == 0:\n",
    "        save_path = saver.save(sess, \"models/pretrained_gan.ckpt\", global_step=i)\n",
    "        print(\"saved to %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see some of the images produced by the generator. (The generator has also been sending its images to TensorBoard regularly; click the \"images\" tab in TensorBoard to see them as this runs.)\n",
    "\n",
    "And, as a sanity check, let's look at some real MNIST images and make sure that the discriminator correctly classifies them as real MINST images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_images = sess.run(generator(10, 100))\n",
    "test_eval = sess.run(discriminator(x_placeholder), {x_placeholder: test_images})\n",
    "\n",
    "real_images = mnist.validation.next_batch(10)[0].reshape([10, 28, 28, 1])\n",
    "real_eval = sess.run(discriminator(x_placeholder), {x_placeholder: real_images})\n",
    "\n",
    "# Show discriminator's probabilities for the generated images,\n",
    "# and display the images\n",
    "for i in range(10):\n",
    "    print(test_eval[i])\n",
    "    plt.imshow(test_images[i, :, :, 0], cmap='Greys')\n",
    "    plt.show()\n",
    "\n",
    "# Now do the same for real MNIST images\n",
    "for i in range(10):\n",
    "    print(real_eval[i])\n",
    "    plt.imshow(real_images[i, :, :, 0], cmap='Greys')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One note that I’d like to make is that GANs are notoriously difficult to train. \n",
    "Without the right hyperparameters, network architecture, and training procedure, \n",
    "there is a high chance that either the generator or discriminator will overpower the other. \n",
    "A common case of this is the situation where the generator is able to find a flaw in the discriminator \n",
    "by repeatedly outputting an image that fits the data distribution the discriminator is looking for, \n",
    "but is nowhere close to being a readable MNIST digit. The generator has collapsed onto a single point, \n",
    "and therefore we won’t output a variety of digits. There are also cases where the discriminator becomes\n",
    "too powerful and is able to easily make the distinction between real and fake images.\n",
    "The mathematical intuition behind this phenomenon lies in that GANs are typically trained using gradient \n",
    "descent techniques that are designed to find the minimum value of a cost function, rather than to find \n",
    "the Nash equilibrium of a game. When used to seek for a Nash equilibrium, these algorithms may fail to \n",
    "converge. Further research into game theory and stable optimization techniques may result in GANs that \n",
    "are as easy to train as ConvNets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
